{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXzOTRVHYVgjVjtHnmwCa0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samhdez03/Ciencia-de-datos/blob/main/Tarea_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tarea 6\n",
        "\n",
        "#Samantha Hernández Caballero\n",
        "#Ejercicio 3 con Ricardo Gutierrez Argüelles"
      ],
      "metadata": {
        "id": "qptMgNPbCKT0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. \n",
        "Considera un esquema de clasificación multiclase con etiquetas $y \\epsilon  \\{1,2, ..., K\\}$ y una matriz de costos asociada $\\Lambda|KxK$, con entradas $\\lambda_{ kj} \\ge 0 $ que representan un error de clasificación, es decir, el costo de clasificar un dato de la clase $j$ como clase $k$, tal como lo vimos en clase. Vimos también, que el riesgo esperado se minimiza asignando la categoría $y_k$ a cada observación x tal que se minimice la expresión\n",
        "\n",
        "$$\n",
        "\\hat{y} = argmin_{y_k} R(y = y_k|x) =\\sum _{j}  \\lambda_{kj} P(y = y_j|x)\n",
        "$$\n",
        "\n",
        "\n",
        "Verifica que, cuando la matriz de costos es $\\Lambda = 1 - I$, lo anterior se reduce al clasificador óptimo Bayesiano. En este caso, **1** e **I** son las matrices de unos y la identidad, respectivamente. ¿Cuál es la interpretación de ésta forma de definir la matriz de costos?"
      ],
      "metadata": {
        "id": "w2i3woR7-wjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la matriz de costos $\\Lambda$, los elementos en la diagonal principal son cero ($\\lambda_{kk}=0$), lo que significa que no hay costo en clasificar correctamente una observación en la clase $k$. Los elementos fuera de la diagonal principal son iguales ($\\lambda_{kj}=1$ para $k \\neq j$), lo que significa que el costo de clasificar incorrectamente una observación en la clase $k$ como perteneciente a la clase $j$ es igual a 1. Esto se puede interpretar como que todos los errores de clasificación tienen el mismo costo. En este caso, el costo esperado de clasificar una observación como de la clase $k$ se reduce a:\n",
        "\n",
        "$$C(k∣x)=\\sum^K_{j=1}  (1−δ_{kj})P(y=j∣x)\n",
        "$$\n",
        "\n",
        "donde $\\delta_{kj}$ es la delta de Kronecker, que es igual a 1 si $k=j$ y 0 en otro caso.\n",
        "\n",
        "La delta de Kronecker es una función matemática que toma dos argumentos enteros y devuelve 1 si los argumentos son iguales y 0 si son diferentes.\n",
        "\n",
        "En el caso de la matriz de costos $\\Lambda = 1 - I$, donde $I$ es la matriz identidad, la delta de Kronecker juega un papel importante. Podemos expresar la matriz $\\Lambda$ como:\n",
        "\n",
        "\n",
        " $$\n",
        " \\begin{equation*}\n",
        "  \\Lambda_{kj}\n",
        "\\left\\{\n",
        "\\begin{aligned}\n",
        "1 \\text{ si k} \\neq j \\\\\n",
        "0 \\text{ si k} = j\n",
        "\\end{aligned}\n",
        "\\right.\n",
        "\\end{equation*}$$\n",
        "\n",
        "En otras palabras, la matriz de costos $\\Lambda$ tiene un costo unitario ($\\lambda_{kj}=1$) para las clasificaciones incorrectas (clase $k$ asignada a $j$ cuando en realidad es de otra clase), y un costo de cero ($\\lambda_{kj}=0$) para las clasificaciones correctas (clase $k$ asignada a $k$). Esta forma particular de definir la matriz de costos es útil porque se traduce directamente en el enfoque Bayesiano, donde se busca minimizar el riesgo esperado.\n",
        "\n",
        "La delta de Kronecker en esta matriz de costos se usa para representar la igualdad o desigualdad de las etiquetas de las clases. En otras palabras, si la etiqueta de la clase verdadera es $j$, entonces el costo de clasificarla incorrectamente como $k$ es 1, que es la contribución de $\\delta_{kj}$ a la matriz de costos.\n",
        "\n",
        "Al minimizar esta expresión, se busca encontrar la clase que maximiza la probabilidad a posteriori condicional $P(y=k|x)$. Es decir, se reduce a encontrar la clase óptima en el enfoque Bayesiano. En resumen, al definir la matriz de costos como $\\Lambda=1-I$, se está considerando que todos los errores de clasificación tienen el mismo costo y se está reduciendo el problema a encontrar la clase óptima en el enfoque Bayesiano."
      ],
      "metadata": {
        "id": "KzaG7Hi9G_Hr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.\n",
        "\n",
        "Considera un problema de clasificación binaria con datos en una dimensión, es decir $x \\epsilon \\mathbb R$, y $\\epsilon \\{1,2\\}$, donde la solución consiste en asignar $y=1$ si $x>\\theta$, y $y=2$ en caso contrario.\n",
        "\n",
        "###a)\n",
        "\n",
        "Muestra que la probabilidad de error para ésta regla de decisión está dada por \n",
        "$$P(error)=P(y=1)\\int\\limits ^\\theta _{-\\infty} P(x|y=1)dx+P(y=2) \\int \\limits^\\infty _\\theta P(x|y=2)dx$$"
      ],
      "metadata": {
        "id": "re_e85FDCbiN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero se utiliza el teorema de la probabilidad total para expresar $P(error)$ como una suma de las probabilidades de error condicionales a cada clase, es decir:\n",
        "$$P(error)=P(y=1)P(error∣y=1)+P(y=2)P(error∣y=2)$$\n",
        "\n",
        "A continuación se utiliza la definición de probabilidad condicional para reescribir $P(error|y=k)$ como una integral de la función de densidad de probabilidad $P(x|y=k)$ sobre la región del espacio de características en la que se produce un error, es decir:\n",
        "$$P(error∣y=k)=\\int_{R_k} P(x∣y=k)dx$$\n",
        "donde $R_k$ es la región del espacio de características en la que la regla de decisión asigna la clase incorrecta. En este caso, $R_1$ es el conjunto de valores $x$ menores o iguales a $\\theta$, mientras que $R_2$ es el conjunto de valores $x$ mayores que $\\theta$.\n",
        "\n",
        "La probabilidad de error para la clase $y=1$ es la probabilidad de que la regla de decisión asigne la clase 2 a una observación que pertenece a la clase 1, es decir:\n",
        "\n",
        "$$P(error∣y=1)=P(x\\leq \\theta ∣y=1)=\\int_{−\\inf}^θ P(x∣y=1)dx$$\n",
        "\n",
        "De manera similar, la probabilidad de error para la clase $y=2$ es la probabilidad de que la regla de decisión asigne la clase 1 a una observación que pertenece a la clase 2, es decir:\n",
        "\n",
        "$$P(error∣y=2)=P(x>\\theta∣y=2)=\\int_θ^\\inf P(x∣y=2)dx$$\n",
        "\n",
        "Finalmente, se sustituyen estas expresiones en la ecuación (1) para obtener la fórmula final:\n",
        "\n"
      ],
      "metadata": {
        "id": "ftqoy2x3TyFv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align*}\n",
        "P(\\text{error}) &= P(y=1, x\\leq \\theta) + P(y=2, x > \\theta) \\\\\n",
        "&= P(y=1) P(x \\leq \\theta | y=1) + P(y=2) P(x > \\theta | y=2) \\\\\n",
        "&= P(y=1) \\int_{-\\infty}^{\\theta} P(x | y=1) dx + P(y=2) \\int_{\\theta}^{\\infty} P(x | y=2) dx\n",
        "\\end{align*}\n",
        "\n"
      ],
      "metadata": {
        "id": "m6gp0FRzSKzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###b)\n",
        "\n",
        "Muestra que $\\theta$ que minimiza $P(error)$ es aquella que satisface \n",
        "\n",
        "$$ P(\\theta | y=1) P(y=1)=P(\\theta|y=2)P(y=2) $$"
      ],
      "metadata": {
        "id": "A3HX34UCGiy8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para encontrar el valor de $\\theta$ que minimiza $P(error)$, necesitamos encontrar el punto crítico de la función $P(error)$, es decir, necesitamos encontrar $\\theta$ tal que la derivada de $P(error)$ con respecto a $\\theta$ sea igual a cero. Podemos escribir la probabilidad de error como:\n",
        "\n",
        "$$ P(error)=P(y=1) \\int_{-\\infty}^{\\theta} P(x | y=1) dx + P(y=2) \\int_{\\theta}^{\\infty} P(x | y=2) dx$$\n",
        "\n",
        "Entonces, la derivada de $P(error)$ con respecto a $\\theta$ es:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial\\theta}{\\partial} P(error)=P(y=1)P(\\theta∣y=1)−P(y=2)P(\\theta∣y=2)$$\n",
        "\n",
        "Igualando esta expresión a cero, obtenemos:\n",
        "\n",
        "$$P(y=1)P(θ∣y=1)=P(y=2)P(θ∣y=2)$$\n",
        "\n",
        "Dividiendo ambos lados por $P(y=1)$, obtenemos la expresión deseada:\n",
        "\n",
        "$$ P(θ∣y=1)P(y=1)=P(θ∣y=2)P(y=2)$$\n",
        "\n",
        "Esta expresión nos dice que la probabilidad de $\\theta$ dada la clase $y=1$ multiplicada por la probabilidad a priori de $y=1$ es igual a la probabilidad de $\\theta$ dada la clase $y=2$ multiplicada por la probabilidad a priori de $y=2$. En otras palabras, la probabilidad a posteriori de que $\\theta$ pertenezca a la clase $y=1$ es igual a la probabilidad a posteriori de que $\\theta$ pertenezca a la clase $y=2$. La solución $\\theta$ que satisface esta igualdad es la que minimiza la probabilidad de error."
      ],
      "metadata": {
        "id": "ytghKLmYXID1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###c)\n",
        "\n",
        "La ecuación anterior ¿define de manera única a $\\theta$ ? explica porqué si, o porqué no, o da un ejemplo\n",
        "\n"
      ],
      "metadata": {
        "id": "SyYfmFrlG92W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ P(θ∣y=1)P(y=1)=P(θ∣y=2)P(y=2)$$\n",
        "\n",
        "Es una relación entre las probabilidades de observar $\\theta$ dada cada clase, ponderadas por la probabilidad de cada clase. Esta relación es independiente de si se busca minimizar el error de clasificación o no. Por lo tanto, la solución $\\theta$ que satisface esta relación es única, independientemente de cómo se haya obtenido.\n",
        "\n",
        "Dicho de otra manera, si se encuentra un valor de $\\theta$ que minimiza el error de clasificación, este valor necesariamente satisfará la relación anterior. Y si se encuentra un valor de $\\theta$ que satisface la relación, este valor necesariamente minimizará el error de clasificación. Por lo tanto, la relación no afecta la unicidad de la solución."
      ],
      "metadata": {
        "id": "Xlbd3zQ2ZAwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.\n",
        "\n",
        "Los datos MNIST contienen dígitos escritos a mano y digitalizados en imágenes en escala de grises de tamaño 28x28 pixeles. Para mayor facilidad, puse los datos en archivos csv:(mnist_Xtrain.csv, mnist_Ytrain.csv) contienen los valores de los pixeles (normalizados) y su respectiva categoría para entrenamiento, y (mnist_Xtest.csv, mnist_Ytest.csv), los mismo para los datos de prueba. Cada dígito está representado como un vector renglón de tamaño 784, y su respectiva categoría, como un vector *one-hot* de tamaño 10. La figura 1 muestra un ejemplo de éstos datos, el cual se generó con el Código MNIST.\n",
        "\n",
        "\n",
        "En este ejercicio implementarás un método de clasificación para los $k\\epsilon K=\\{0,1,...,9\\}$ dígitos.\n",
        "\n",
        "###a)\n",
        "\n",
        "Implementa el *baseline* que usaremos. Este será un método de regresión multivariada, es decir \n",
        "\n",
        "$$Y=X\\hat{B},$$\n",
        "\n",
        "donde $Y_{nx|K|}$ es una matriz indicadora, donde cada renglón tiene ceros excepto en el lugar que corresponde al valor $y_k$, donde colocamos un 1. Por ejemplo, si alguna imagen corresponde al dígito \"3\", el renglón correspondiente en Y será (0,0,0,1,0,0,0,0,0,0).\n",
        "\n",
        "$X_{nx784}$ es la matriz de características y $\\hat{B}$ es la matriz cuyas columnas contienen los $|K|$ coeficientes correspondientes $\\hat{\\beta}_k.$\n",
        "\n",
        "Con esta formulación, asumimos un modelo lineal para cada respuesta $y_k$:\n",
        "\n",
        "$$\\hat{y}_k X\\hat{\\beta} _k,$$\n",
        "\n",
        "y la clasificación para alguna observación x se obtiene mediante\n",
        "\n",
        "$$\\hat{C}(x)=arg max_{k\\epsilon K} \\hat{y}_k.$$\n",
        "\n",
        "Utiliza los datos train y test para ajustar y probar el modelo, respectívamente.\n",
        "\n",
        "Puedes restringir el número de observaciones de cada conjunto, pero procura que el conjunto de entrenamiento sea más grande que el de prueba. Reporta todas las métricas de desempeño que vimos, y también el error cuadrático medio.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rABzDOtwHK24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "from sklearn import tree, model_selection, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/4to semestre/Ciencia de datos/Tarea 6')\n",
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/4to semestre/Ciencia de datos/Tarea 6/'\n",
        "\n",
        "Xtest = pd.read_csv('mnist_Xtest.csv', header=None).to_numpy()\n",
        "Xtrain = pd.read_csv('mnist_Xtrain.csv', header=None).to_numpy()\n",
        "Ytest = pd.read_csv('mnist_Ytest.csv', header=None).to_numpy()\n",
        "Ytrain = pd.read_csv('mnist_Ytrain.csv', header=None).to_numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_-nUEXMZZi-9",
        "outputId": "2c1d9672-52cb-4ef6-b744-31fb93ece552"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generamos la etiqueta de los datos de acuerdo a la columna en la que se identifica el número"
      ],
      "metadata": {
        "id": "AC-D13ava-0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, Ytrain_label=np.where(Ytrain==1)\n",
        "_, Ytest_label=np.where(Ytest==1)"
      ],
      "metadata": {
        "id": "0Q-iPIrna_Nm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure=plt.figure(figsize=(12,3))\n",
        "cols, rows=8,2\n",
        "for i in range(1, cols*rows+1):\n",
        "    sample_idx=np.random.choice(len(Ytrain_label), 1)[0]\n",
        "    img, label=Xtrain[sample_idx].reshape((28,28)), Ytrain_label[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(label)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "-llTtHvXbhrE",
        "outputId": "fd838392-6a9a-4d36-978c-d2f69debdb22"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x300 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresión lineal"
      ],
      "metadata": {
        "id": "BRxtpwtMbt96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg_lin=LinearRegression()\n",
        "reg_lin.fit(Xtrain, Ytrain_label)\n",
        "\n",
        "error_cuad=reg_lin.score(Xtrain, Ytrain_label)\n",
        "\n",
        "print(\"intercepto:\", reg_lin.intercept_) #interceptos para las 10 columnas\n",
        "print(\"coeficientes\", reg_lin.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Xf02Isqqb1fI",
        "outputId": "b4c0788f-bb5a-4d14-baea-3573f5676cac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "intercepto: 3.0192442325015865\n",
            "coeficientes [ 1.73586573e+07 -4.45568296e+11 -9.52806107e+12  7.25435776e+12\n",
            " -1.09884360e+12 -7.23825179e+12  1.00401774e+13 -1.31013090e+12\n",
            "  1.11790673e+11  3.13579901e+12  5.35413902e+12 -1.25647805e+12\n",
            " -1.49296324e+12  6.81825731e+11 -6.02651908e+11 -2.41323622e+11\n",
            "  2.69954448e+12 -4.98439295e+12 -2.38135303e+12 -5.74371274e+11\n",
            " -2.13204635e+12 -4.86138723e+12 -2.78834614e+12  3.08339725e+11\n",
            " -4.07460647e+11  1.38750658e+12 -1.15753054e+12 -4.02347332e+12\n",
            " -8.12096769e+11 -3.84261540e+12 -1.08747809e+12  2.72330524e+11\n",
            "  1.48891136e+02 -4.58548433e+01  5.77365494e+00 -2.50180626e+00\n",
            "  8.33037376e-01  1.64394379e-01 -7.98091888e-02  3.72314453e-02\n",
            "  1.54819489e-02 -1.05495453e-02  3.41182709e-01  3.30656826e-01\n",
            " -5.45979500e-01  2.29476929e-01  2.26050854e-01 -2.78377533e-03\n",
            "  3.49509239e-01  6.54677868e-01 -1.89169514e+00  2.85303366e+00\n",
            "  2.40605688e+10 -6.19074659e+09  5.29219171e+11 -6.38513214e+11\n",
            "  1.46983320e+11 -9.79472216e+10  8.40691577e+01 -2.13303871e+01\n",
            "  1.37659812e+00 -1.20807728e+00  8.21428537e-01  1.82519436e-01\n",
            "  7.46939182e-01  5.07343292e-01  7.92510986e-01  2.18284607e-01\n",
            "  6.46232605e-01  3.57873917e-01  5.92388630e-01  1.76048279e-01\n",
            "  7.60574341e-01  2.58331299e-01  5.81436157e-01  3.07601929e-01\n",
            "  5.49880981e-01  1.24618530e-01  8.76243591e-01 -1.11368847e+00\n",
            "  1.59416962e+00 -5.72911525e+00  3.86087666e+11 -6.22607869e+11\n",
            "  4.21683316e+10 -1.01774651e+11 -3.84667836e+01  1.94429636e+00\n",
            "  2.09926939e+00 -8.23547363e-01  9.99935150e-01  1.43951416e-01\n",
            "  7.79724121e-02  2.30834961e-01  3.43200684e-01 -1.46118164e-01\n",
            "  1.30371094e-01  4.77294922e-02  1.79931641e-01  2.18872070e-01\n",
            "  1.88232422e-01  2.02514648e-01  5.62622070e-01  3.66897583e-01\n",
            "  7.33154297e-01  6.17736816e-01  8.19168091e-01  6.95709229e-01\n",
            "  1.57796860e+00 -1.49129701e+00  5.65347457e+00  4.09476167e+11\n",
            "  2.40777888e+11  4.79215963e+00  4.84587979e+00  2.01238519e+00\n",
            "  6.86227798e-01  1.49444580e-01 -2.42568970e-01  1.57043457e-01\n",
            "  2.32543945e-02  1.12182617e-01  1.05163574e-01  1.24816895e-01\n",
            " -1.75415039e-01 -1.34643555e-01  5.82885742e-02 -1.07666016e-01\n",
            " -2.46582031e-02 -7.95898438e-02 -1.06079102e-01 -9.48791504e-02\n",
            " -1.05957031e-01 -7.44628906e-03 -2.73437500e-02  1.57836914e-01\n",
            "  5.19348145e-01  1.66168213e-01  2.47772217e-01  8.78352806e+00\n",
            "  7.10533829e+10 -1.94084861e+11  2.76299286e+00 -4.89876747e-01\n",
            "  5.47103882e-02 -1.99630737e-01 -9.16748047e-02 -5.84106445e-02\n",
            "  1.36413574e-01 -1.76391602e-02  5.47180176e-02 -2.67333984e-02\n",
            "  2.15270996e-01 -1.90139771e-01 -5.79833984e-03 -1.52343750e-01\n",
            " -9.69848633e-02 -7.55615234e-02  9.74121094e-02 -6.49414062e-02\n",
            "  1.10412598e-01 -8.35876465e-02  1.36718750e-01 -5.48095703e-02\n",
            "  2.90771484e-01  5.37872314e-01  3.89074326e-01  3.85033202e+00\n",
            " -3.85280080e+10 -3.08999618e+01 -3.93850327e-01 -3.68684769e-01\n",
            " -6.53076172e-02  3.95050049e-01 -1.17797852e-02  1.33056641e-02\n",
            " -3.95507812e-02  9.57031250e-02  2.51464844e-02  5.17578125e-02\n",
            " -9.76562500e-04  4.07714844e-02  6.56433105e-02  1.02966309e-01\n",
            "  1.11083984e-01  2.17041016e-01 -3.39355469e-02  1.12182617e-01\n",
            " -1.23901367e-01 -7.14111328e-03 -2.27203369e-02  6.56738281e-02\n",
            " -2.42919922e-02  3.59233856e-01 -3.57933044e-02  3.52869987e-01\n",
            "  7.00753401e+01  5.26628494e-02  1.55686402e+00  1.77124023e-01\n",
            " -2.52325058e-01 -1.00387573e-01 -4.41894531e-02 -3.80859375e-02\n",
            "  1.07177734e-01 -7.05566406e-02  1.19140625e-01  2.68554688e-03\n",
            "  3.32031250e-02  2.79235840e-03  1.15356445e-02  1.90748215e-01\n",
            "  1.02294922e-01 -1.42089844e-01 -2.31933594e-02 -2.07824707e-01\n",
            "  5.97534180e-02  2.18505859e-02 -2.06970215e-01  7.26318359e-02\n",
            "  4.94598389e-01 -1.39129639e-01  5.07965088e-02  3.52781296e-01\n",
            " -1.79411594e+01 -1.87787056e+00  3.81050110e-02 -2.27662086e-01\n",
            "  1.87488556e-01 -1.19506836e-01 -6.37817383e-02  1.17919922e-01\n",
            "  1.23184204e-01  4.76074219e-03  5.10864258e-02  9.13696289e-02\n",
            "  3.33251953e-02  5.68847656e-02 -2.84423828e-02 -2.85644531e-02\n",
            " -1.95312500e-02 -1.45996094e-01 -9.17968750e-02 -1.83105469e-03\n",
            " -1.64642334e-01  5.23681641e-02  2.22778320e-02  1.67236328e-01\n",
            "  3.61389160e-01  6.62506104e-01 -4.95204926e-02 -1.72262192e-02\n",
            "  7.31886250e+00 -3.68766785e-02  1.24153137e-01  4.80728149e-01\n",
            " -3.35327148e-01  9.17358398e-02  2.20947266e-02 -1.06300354e-01\n",
            "  1.05346680e-01  1.43646240e-01  6.89697266e-02  2.21191406e-01\n",
            "  2.03125000e-01 -1.09985352e-01 -6.63452148e-02 -1.51489258e-01\n",
            " -7.39746094e-02 -6.68945312e-02 -1.13281250e-01 -1.22192383e-01\n",
            "  5.47485352e-02  5.16662598e-02 -3.13720703e-02 -2.41699219e-02\n",
            "  3.60717773e-01  4.08203125e-01  9.09709930e-02  1.12762403e+00\n",
            " -4.97595572e+00  7.03311920e-01  3.11653137e-01 -2.33306885e-01\n",
            "  2.48260498e-01 -1.32934570e-01  1.85913086e-01 -9.76562500e-04\n",
            "  1.49627686e-01  9.49096680e-03  2.53906250e-01  1.80908203e-01\n",
            "  1.09497070e-01 -3.61328125e-02 -3.48144531e-01 -2.57568359e-01\n",
            " -2.09960938e-02 -1.51611328e-01 -1.83105469e-02  9.09423828e-02\n",
            " -1.98608398e-01 -1.01470947e-01  4.83398438e-02  7.25097656e-02\n",
            " -5.60913086e-02  4.29290771e-01  4.22203064e-01 -1.38564205e+00\n",
            "  4.49341345e+00 -5.14500618e-01  5.16883850e-01 -2.90664673e-01\n",
            " -2.36816406e-01  1.82128906e-01  1.55029297e-02  2.23022461e-01\n",
            "  2.02941895e-01  2.45361328e-01  1.04492188e-01  1.62109375e-01\n",
            "  3.79882812e-01  3.27392578e-01 -1.45263672e-01 -1.92382812e-01\n",
            "  3.02734375e-02  1.23596191e-01  4.02832031e-02 -9.69238281e-02\n",
            "  1.34765625e-01 -7.06787109e-02  2.25219727e-02 -2.22656250e-01\n",
            "  1.16760254e-01  1.14859009e+00  1.95800781e-01  8.60974789e-02\n",
            " -3.86318719e+00  1.35579395e+00 -4.50096130e-02 -8.14208984e-02\n",
            "  1.65771484e-01  3.31665039e-01  2.02392578e-01  8.86230469e-02\n",
            " -9.54589844e-02  1.20361328e-01  3.66210938e-03  2.04589844e-01\n",
            "  2.14111328e-01  2.99072266e-01 -2.76611328e-01  1.09619141e-01\n",
            "  2.33398438e-01  2.19604492e-01  1.06201172e-01  1.71722412e-01\n",
            " -1.00097656e-01  1.06201172e-01  1.28784180e-01  2.60009766e-02\n",
            " -3.54949951e-01 -4.89807129e-01  1.64830446e-01  1.80498981e+00\n",
            " -4.75093365e+00  5.75409889e-01 -4.86236572e-01  2.46643066e-01\n",
            "  5.47241211e-01  1.18286133e-01  8.32519531e-02  7.10220337e-02\n",
            "  2.02148438e-01  2.53906250e-02  6.34765625e-03 -5.24902344e-02\n",
            "  4.98535156e-01  9.32617188e-02 -3.30322266e-01  3.81347656e-01\n",
            "  1.63452148e-01  2.05322266e-01  1.49658203e-01  1.75811768e-01\n",
            "  1.40136719e-01  7.25097656e-02 -1.33972168e-01 -3.29338074e-01\n",
            "  2.12600708e-01  2.14323044e-01 -1.09402919e+00 -2.11120081e+00\n",
            "  2.18367495e+10 -3.56633663e-01  7.77647495e-01  3.32794189e-01\n",
            "  9.83276367e-02  6.29272461e-02 -1.44042969e-01 -1.64306641e-01\n",
            " -1.32812500e-01 -5.88378906e-02 -2.79052734e-01  1.51000977e-01\n",
            "  4.12109375e-01 -2.41699219e-01  2.21771240e-01 -1.23718262e-01\n",
            "  3.07006836e-01  1.51000977e-01 -7.43408203e-02  2.34832764e-02\n",
            " -1.11938477e-01 -2.89794922e-01 -1.73339844e-02 -3.91998291e-02\n",
            "  5.09643555e-03  9.39445496e-02 -1.73528862e+00 -2.19020951e+00\n",
            " -6.66906093e+10  2.10572588e+00  6.89158440e-02 -9.96780396e-03\n",
            " -1.23046875e-01 -4.13909912e-01 -5.11779785e-02 -8.83789062e-02\n",
            " -1.77734375e-01 -6.71386719e-02 -5.20019531e-02  1.00891113e-01\n",
            "  2.14538574e-01 -1.50817871e-01  6.99615479e-02 -4.17480469e-02\n",
            "  3.64257812e-01  8.08105469e-02  4.54711914e-02 -4.91943359e-02\n",
            " -7.93457031e-02  8.38623047e-02  3.60717773e-02 -1.11892700e-01\n",
            "  1.25122070e-01  4.94949341e-01 -4.21766043e-01 -1.17201805e+00\n",
            "  1.16708561e+10 -3.73833728e+00 -1.23294067e+00  6.26804352e-01\n",
            " -4.89349365e-02 -4.86450195e-02 -5.00259399e-02 -2.25524902e-02\n",
            " -7.87353516e-02 -1.15417480e-01  1.89208984e-02  2.00744629e-01\n",
            "  2.22473145e-01 -1.25732422e-01 -1.41113281e-01  1.27441406e-01\n",
            "  2.55859375e-01 -3.07617188e-02 -2.01690674e-01 -1.21520996e-01\n",
            " -5.34667969e-02 -2.33886719e-01  1.31652832e-01 -1.37268066e-01\n",
            " -2.06169128e-01 -2.07761765e-01 -9.73924637e-01  8.06022644e-01\n",
            " -2.05349057e+10 -3.97840786e+00  4.44262505e-01  1.99323654e-01\n",
            " -4.22897339e-02 -5.31005859e-03 -2.13256836e-01 -1.68151855e-01\n",
            "  4.41894531e-02  6.85729980e-02  8.11767578e-03  2.54211426e-01\n",
            "  1.14807129e-01 -3.24707031e-02 -5.00488281e-02  1.48437500e-01\n",
            "  6.68945312e-02 -6.29882812e-02  9.03320312e-03 -2.01171875e-01\n",
            "  6.05468750e-02 -4.40673828e-02 -2.40753174e-01  6.16149902e-02\n",
            "  3.55895996e-01 -6.07112885e-01 -9.38646317e-01 -4.67896509e+00\n",
            "  1.01009345e+01  3.34574842e+00 -4.42142487e-01  3.35407257e-01\n",
            " -1.35574341e-02 -2.35412598e-01  9.72900391e-02 -1.06445312e-01\n",
            " -1.83227539e-01  1.13403320e-01  2.15637207e-01  2.17651367e-01\n",
            " -7.23876953e-02 -1.41113281e-01  2.83203125e-02 -3.80859375e-02\n",
            " -4.49218750e-02 -3.41796875e-03 -2.56347656e-03 -5.41992188e-02\n",
            " -1.00097656e-02 -1.60522461e-02  8.54492188e-03 -3.14025879e-02\n",
            " -6.50695801e-01  1.54384613e-01  9.30973053e-01 -1.42684603e+00\n",
            " -2.44803350e+01  6.82846546e-01  3.06232452e-01 -3.94515991e-01\n",
            "  1.93191528e-01 -2.94189453e-02 -6.46972656e-02 -1.10961914e-01\n",
            "  7.35626221e-02 -1.00402832e-01  4.13665771e-02 -1.83105469e-03\n",
            "  6.24389648e-02 -4.03198242e-01 -6.27441406e-02 -5.90820312e-02\n",
            "  3.39355469e-02 -6.50634766e-02 -7.66601562e-02 -1.80053711e-02\n",
            " -8.15429688e-02 -1.92481995e-01 -3.63159180e-03 -7.59887695e-02\n",
            "  6.78253174e-03 -6.41635895e-01 -1.13970947e+00  1.72685742e+00\n",
            "  1.73615265e+10 -2.23316240e+00  1.33251190e-01  1.20361328e-01\n",
            " -3.46313477e-01  9.55200195e-02 -1.12915039e-01  1.26953125e-02\n",
            " -3.88488770e-02 -1.35437012e-01 -2.23999023e-02 -1.77795410e-01\n",
            "  2.28271484e-02  5.77392578e-02 -1.41113281e-01  2.25830078e-02\n",
            " -9.96093750e-02 -1.16851807e-01 -1.04248047e-01 -1.05957031e-01\n",
            " -1.13475800e-01 -1.37695312e-01  6.43310547e-02 -1.10015869e-01\n",
            " -3.36364746e-01  1.32190704e-01  4.94442940e-01 -2.32392502e+00\n",
            "  3.00938448e+09  5.92873812e-01  3.79238129e-01 -4.20913696e-01\n",
            " -5.02929688e-02 -8.17871094e-03  3.26957703e-02  7.23876953e-02\n",
            " -7.72705078e-02 -1.16943359e-01 -1.40792847e-01 -6.65283203e-02\n",
            "  4.37011719e-02 -7.08007812e-03 -4.71801758e-02 -1.70166016e-01\n",
            "  1.28173828e-02 -6.59179688e-03  2.02636719e-02  3.90625000e-03\n",
            "  9.50622559e-02 -2.41577148e-01  4.70581055e-02 -1.23565674e-01\n",
            "  8.91113281e-03 -5.89645386e-01 -1.46481514e+00 -8.59515764e+09\n",
            " -3.10646144e+09  1.61331924e+01 -2.95791626e-01 -7.95898438e-02\n",
            "  1.00585938e-01 -6.76269531e-02 -5.54199219e-02 -1.13952637e-01\n",
            " -7.64160156e-02 -1.97998047e-01  2.49023438e-02  4.88281250e-04\n",
            "  7.42187500e-02 -1.61132812e-02  2.56347656e-03 -1.07360840e-01\n",
            "  6.34765625e-03 -7.98339844e-02  4.16259766e-02 -2.40600586e-01\n",
            " -9.67102051e-02  3.11279297e-03 -1.38519287e-01 -1.78405762e-01\n",
            " -1.42486572e-01 -3.28651786e-01  1.98374271e-01  4.65571034e+09\n",
            "  3.67852512e+08 -4.94251424e+09 -4.06265259e-01  4.22973633e-01\n",
            " -1.86737061e-01 -8.65478516e-02  9.80224609e-02 -2.93395996e-01\n",
            "  1.29760742e-01 -1.57470703e-01 -1.36718750e-02 -5.98144531e-02\n",
            " -2.34375000e-02  5.02929688e-02  4.67529297e-02 -1.53106689e-01\n",
            " -1.23046875e-01 -8.78906250e-03  1.77001953e-02  2.71606445e-02\n",
            " -1.41906738e-03 -9.32617188e-02  1.95823669e-01 -1.79763794e-01\n",
            "  2.59963989e-01 -1.06853485e-01 -4.36708593e+00 -9.10529425e+09\n",
            " -2.44958422e+09  8.10809951e+09  1.89796448e+00 -1.61312866e+00\n",
            "  6.41113281e-01 -1.95312500e-02 -6.15722656e-01  1.69799805e-01\n",
            " -4.37393188e-02  1.95312500e-03  6.99462891e-02  1.73339844e-02\n",
            "  1.78833008e-02  2.99072266e-03  5.23681641e-02  1.38549805e-02\n",
            "  9.31396484e-02 -1.34887695e-02 -1.03485107e-01  1.81259155e-01\n",
            "  4.55282211e-01  9.30843353e-02 -9.75055695e-02  1.67739868e+00\n",
            " -4.35276031e-02 -4.92529202e+00 -1.94801247e+01  5.69414016e+08\n",
            "  8.84703497e+08  1.66783957e+07  1.64019680e+00  6.78722382e-01\n",
            " -1.13250732e+00  1.77343750e+00  3.53393555e-01  1.00158691e+00\n",
            "  3.81225586e-01  4.57000732e-01  4.91455078e-01  3.92547607e-01\n",
            "  5.04394531e-01  4.16748047e-01  3.09936523e-01  5.65307617e-01\n",
            "  6.33903503e-01  8.85589600e-01  8.94744873e-01  6.94763184e-01\n",
            "  9.44805145e-01  1.47653961e+00  1.48712158e-01  4.89295959e-01\n",
            "  8.02688599e-01  1.79042472e+01  2.03210050e+00  3.05175781e-05\n",
            " -1.52587891e-05  3.05175781e-05  6.10351562e-05  8.64983535e+00\n",
            "  1.86994171e+00  6.23214722e-01  2.67257690e-01  4.25796509e-01\n",
            "  4.83093262e-01  6.33964539e-01  2.43377686e-01  5.29083252e-01\n",
            "  3.53881836e-01  5.82946777e-01  7.27111816e-01  4.21600342e-01\n",
            "  6.28326416e-01  1.05281830e-01  6.47361755e-01  1.12442017e-01\n",
            "  3.43620300e-01  1.96080685e-01 -5.22687435e-02  2.16965723e+00\n",
            "  1.53011859e+01  6.83833355e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            " -2.26291227e+00 -2.89426804e-01  5.86284161e-01  5.58979034e-01\n",
            " -5.42778015e-01  1.00830078e-01  3.93553734e-01 -2.60374069e-01\n",
            "  6.33995056e-01 -5.14175415e-01  6.03736877e-01 -8.77380371e-02\n",
            "  3.58295441e-03  6.32991791e-02  2.47819424e-02 -1.16190100e+00\n",
            "  9.52808380e-01 -1.69294906e+00  4.77711344e+00 -3.30378777e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicción de la regresión\n",
        "y_pred = reg_lin.predict(Xtest)\n",
        "df_comparar=pd.DataFrame({'Actual': Ytest_label.flatten(), 'Predicted': y_pred.flatten()})\n",
        "df_comparar\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "TRLIPjA2b2NO",
        "outputId": "4e9c5f96-81a5-447e-dc3a-99b3afab26bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Actual  Predicted\n",
              "0          7   6.309666\n",
              "1          2   2.330394\n",
              "2          1   1.622624\n",
              "3          0   0.991218\n",
              "4          4   4.368339\n",
              "...      ...        ...\n",
              "9995       2   2.802150\n",
              "9996       3   1.959181\n",
              "9997       4   7.870737\n",
              "9998       5   5.497467\n",
              "9999       6   5.776149\n",
              "\n",
              "[10000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7b91f05-c851-40d6-8f0d-36487a4f43d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>6.309666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2.330394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1.622624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.991218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4.368339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>2</td>\n",
              "      <td>2.802150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>3</td>\n",
              "      <td>1.959181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>4</td>\n",
              "      <td>7.870737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>5</td>\n",
              "      <td>5.497467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>6</td>\n",
              "      <td>5.776149</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7b91f05-c851-40d6-8f0d-36487a4f43d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7b91f05-c851-40d6-8f0d-36487a4f43d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7b91f05-c851-40d6-8f0d-36487a4f43d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El error cuadrático medio es de 0.616, lo cual es un valor aceptable. En el caso del Error Absoluto Medio y el error cuadrático medio arroja resultados muy elevados."
      ],
      "metadata": {
        "id": "5PoGbGAFb9Gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"R2:\", error_cuad)\n",
        "print('MAE:', metrics.mean_absolute_error(Ytest_label, y_pred))\n",
        "print('MSE:', metrics.mean_squared_error(Ytest_label, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ALizAXmyb_Mp",
        "outputId": "badb1224-8210-422e-b257-54f34b961618"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2: 0.6160522500480432\n",
            "MAE: 1873200.282505783\n",
            "MSE: 3.508874049311852e+16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###b)\n",
        "\n",
        "\n",
        "Utiliza clasificadores basados en LDA y QDA, verifica si puedes superar al baseline respecto a las métricas que obtuviste. ¿Crees que ayudaría tener otra\n",
        "representación de los dígitos? Explica tu respuesta e impleméntala."
      ],
      "metadata": {
        "id": "szqgPZyXL5QH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LDA"
      ],
      "metadata": {
        "id": "G_lKW2pIcSY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain_df=pd.DataFrame(Xtrain)\n",
        "Ytrain_df=pd.DataFrame(Ytrain)\n",
        "pca=PCA(n_components=2)\n",
        "X_train_r=pca.fit(Xtrain)\n",
        "lda = LinearDiscriminantAnalysis(n_components=2)\n",
        "X_train_r2=lda.fit(Xtrain_df, Ytrain_label).transform(Xtrain_df)\n",
        "print(\n",
        "    \"explained variance ratio (first two components): %s\"\n",
        "    % str(pca.explained_variance_ratio_)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_jB2WY6gcDN3",
        "outputId": "9200165a-6f9a-40fd-cfe2-426cdd248f5c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "explained variance ratio (first two components): [0.09704664 0.07095924]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat=lda.predict(Xtest)"
      ],
      "metadata": {
        "id": "3xWZLhnPeFpL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analizando ahora la precisión del Análisis por Discriminante líneal, vemos que arroja resultados de 0.87, lo cual es cercano a uno, por lo que el desempeño del LDA es muy bueno para clasificar correctamente la predicción. "
      ],
      "metadata": {
        "id": "IoPyktlDeJF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(Ytest_label, y_hat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fD04twUOeMJO",
        "outputId": "eeb382f4-2854-4a33-a3b2-2376e4f64fb9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95       980\n",
            "           1       0.89      0.97      0.93      1135\n",
            "           2       0.92      0.79      0.85      1032\n",
            "           3       0.87      0.87      0.87      1010\n",
            "           4       0.84      0.90      0.87       982\n",
            "           5       0.84      0.82      0.83       892\n",
            "           6       0.91      0.89      0.90       958\n",
            "           7       0.91      0.84      0.88      1028\n",
            "           8       0.80      0.81      0.80       974\n",
            "           9       0.81      0.85      0.83      1009\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QDA"
      ],
      "metadata": {
        "id": "BdXWNJZpeM63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qda=QuadraticDiscriminantAnalysis(store_covariance=False)\n",
        "qda.fit(Xtrain, Ytrain_label)\n",
        "y_hatq=qda.predict(Xtest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UIMYapA0ebJ1",
        "outputId": "6c15a4ed-65d2-41cf-8358-f3fbe55f9610"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el caso del Análisis por Discriminante Cuadrático, se aprecia resultados aceptables (0.70), aunque no tan\n",
        "buenos como los arrojados por el LDA.\n",
        "Aunque el LDA y el QDA arrojan mejores resultados que los obtenidos por la regresión líneal, el LDA fue el que\n",
        "mejor precisión tuvo a la hora de comparar la clasificación de la variable de respuesta predicha, con respecto a\n",
        "los valores de prueba originales.\n",
        "Cabe señalar que los resultados del LDA y QDA se usaron haciendo una reducción de dimensionalidad (a dos\n",
        "dimensiones) mediante el uso de Componentes Principales (PCA). Aunque pudiera ser que otra representación\n",
        "de los dígitos ayude a mejorar la precisión de la predicción, los resultados obtenidos mediante LDA son muy\n",
        "aceptables, ya que al tener un valor de 0.87, se acerca a un valor cercano a la unidad, lo que significa una\n",
        "clasificación muy buena."
      ],
      "metadata": {
        "id": "zWX28DjVedYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(Ytest_label, y_hatq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iwJ44yfHefcX",
        "outputId": "9e15eb51-61e6-4af2-c294-348c400a2288"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.97      0.51       980\n",
            "           1       0.89      0.95      0.92      1135\n",
            "           2       0.90      0.17      0.29      1032\n",
            "           3       0.62      0.28      0.39      1010\n",
            "           4       0.94      0.12      0.22       982\n",
            "           5       0.83      0.07      0.12       892\n",
            "           6       0.68      0.96      0.79       958\n",
            "           7       0.92      0.30      0.45      1028\n",
            "           8       0.46      0.61      0.53       974\n",
            "           9       0.43      0.94      0.59      1009\n",
            "\n",
            "    accuracy                           0.54     10000\n",
            "   macro avg       0.70      0.54      0.48     10000\n",
            "weighted avg       0.70      0.54      0.49     10000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}